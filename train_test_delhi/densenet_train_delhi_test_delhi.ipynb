{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from astra.torch.models import DenseNetClassifier,DenseNet121_Weights  \n",
    "from astra.torch.utils import train_fn\n",
    "from astra.torch.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved tensors\n",
    "loaded_data = torch.load(\"/home/rishabh.mondal/Brick-Kilns-project/albk_rishabh/tensor_data/test_data.pt\")\n",
    "\n",
    "# Access the tensors\n",
    "index1 = loaded_data['index']\n",
    "images1 = loaded_data['images']\n",
    "labels1 = loaded_data['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10025,) torch.Size([10025, 3, 224, 224]) torch.Size([10025])\n"
     ]
    }
   ],
   "source": [
    "print(index1.shape, images1.shape, labels1.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('<U17'), torch.uint8, torch.uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index1.dtype, images1.dtype, labels1.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified Cross Validation spliting of data into train and test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No need to run this cell, just load the `/home/jaiswalsuraj/suraj_work/Brick-Kilns-Project/data/albk_v2_data/fold_data_delhi.pt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 6737, 1: 781})\n",
      "Counter({0: 2246, 1: 261})\n",
      "Fold 1 - Train: Counter({0: 6737, 1: 781}), Test: Counter({0: 2246, 1: 261})\n",
      "Counter({0: 6737, 1: 782})\n",
      "Counter({0: 2246, 1: 260})\n",
      "Fold 2 - Train: Counter({0: 6737, 1: 782}), Test: Counter({0: 2246, 1: 260})\n",
      "Counter({0: 6737, 1: 782})\n",
      "Counter({0: 2246, 1: 260})\n",
      "Fold 3 - Train: Counter({0: 6737, 1: 782}), Test: Counter({0: 2246, 1: 260})\n",
      "Counter({0: 6738, 1: 781})\n",
      "Counter({0: 2245, 1: 261})\n",
      "Fold 4 - Train: Counter({0: 6738, 1: 781}), Test: Counter({0: 2245, 1: 261})\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from collections import Counter\n",
    "\n",
    "fold_data = []  # List to store data from each fold\n",
    "\n",
    "seed = 42  # Use your desired random seed\n",
    "splitter = StratifiedKFold(n_splits=4, shuffle=True, random_state=seed)\n",
    "images1 = images1 / 255\n",
    "    # mean normalize\n",
    "images1 = (images1 - images1.mean(dim=(0, 2, 3), keepdim=True)) / images1.std(dim=(0, 2, 3), keepdim=True)\n",
    "for fold, (train_idx, test_idx) in enumerate(splitter.split(images1, labels1)):\n",
    "    X_train, X_test = images1[train_idx], images1[test_idx]\n",
    "    y_train, y_test = labels1[train_idx], labels1[test_idx]\n",
    "\n",
    "    # Count occurrences of each class in train and test sets\n",
    "    train_counter = Counter(y_train.numpy())\n",
    "    test_counter = Counter(y_test.numpy())\n",
    "    print(train_counter)\n",
    "    print(test_counter)\n",
    "    print(f\"Fold {fold + 1} - Train: {train_counter}, Test: {test_counter}\")\n",
    "\n",
    "    fold_data.append({\n",
    "        'fold': fold + 1,\n",
    "        'X_train': X_train,\n",
    "        'X_test': X_test,\n",
    "        'y_train': y_train,\n",
    "        'y_test': y_test,\n",
    "        'train_counter': train_counter,\n",
    "        'test_counter': test_counter\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the list of fold data using torch.save\n",
    "# torch.save(fold_data, '/home/jaiswalsuraj/suraj_work/Brick-Kilns-Project/data/albk_v2_data/fold_data_delhi.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:  1\n",
      "trainloader datatype:  torch.uint8\n",
      "testloader datatype:  torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaiswalsuraj/miniconda3/envs/torch_gpu/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Loss: 0.00000115: 100%|██████████| 100/100 [1:03:30<00:00, 38.11s/it]\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9801\n",
      "Precision: 0.9073\n",
      "Recall: 0.9004\n",
      "F1 Score: 0.9038\n",
      "\n",
      "\n",
      "Fold:  2\n",
      "trainloader datatype:  torch.uint8\n",
      "testloader datatype:  torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.00000255: 100%|██████████| 100/100 [26:25<00:00, 15.86s/it] \n",
      "100%|██████████| 10/10 [00:01<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9765\n",
      "Precision: 0.9205\n",
      "Recall: 0.8462\n",
      "F1 Score: 0.8818\n",
      "\n",
      "\n",
      "Fold:  3\n",
      "trainloader datatype:  torch.uint8\n",
      "testloader datatype:  torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.00000097: 100%|██████████| 100/100 [35:37<00:00, 21.37s/it] \n",
      "100%|██████████| 10/10 [00:01<00:00,  8.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9824\n",
      "Precision: 0.9186\n",
      "Recall: 0.9115\n",
      "F1 Score: 0.9151\n",
      "\n",
      "\n",
      "Fold:  4\n",
      "trainloader datatype:  torch.uint8\n",
      "testloader datatype:  torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.00000064: 100%|██████████| 100/100 [28:06<00:00, 16.86s/it]\n",
      "100%|██████████| 10/10 [00:02<00:00,  4.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9808\n",
      "Precision: 0.9209\n",
      "Recall: 0.8927\n",
      "F1 Score: 0.9066\n",
      "\n",
      "\n",
      "Mean Accuracy:  tensor(0.9800, device='cuda:0')\n",
      "Mean Precision:  tensor(0.9168, device='cuda:0')\n",
      "Mean Recall:  tensor(0.8877, device='cuda:0')\n",
      "Mean F1:  tensor(0.9018, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Load the saved fold data from the .pkl file\n",
    "path = '/home/jaiswalsuraj/suraj_work/Brick-Kilns-Project/data/albk_v2_data/fold_data_delhi.pt'\n",
    "fold_data = torch.load(path)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Lists to store metrics for each fold\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "for fold_info in fold_data:\n",
    "    fold = fold_info['fold']\n",
    "    print(\"Fold: \", fold)\n",
    "    X_train = fold_info['X_train']\n",
    "    y_train = fold_info['y_train']\n",
    "    X_test = fold_info['X_test']\n",
    "    y_test = fold_info['y_test']\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "    # Create DataLoader for training and testing\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    # Create and train the model\n",
    "    #print datatype of trainloader\n",
    "    print(\"trainloader datatype: \", train_loader.dataset.tensors[1].dtype)\n",
    "    print(\"testloader datatype: \", test_loader.dataset.tensors[0].dtype)\n",
    "    train_model = DenseNetClassifier    (\n",
    "        models.densenet121, DenseNet121_Weights, n_classes=2, activation=nn.ReLU(), dropout=0.1\n",
    "    ).to(device)\n",
    "\n",
    "    iter_losses, epoch_losses = train_fn(\n",
    "        train_model,\n",
    "        nn.CrossEntropyLoss(),\n",
    "        dataloader=train_loader,\n",
    "        lr=3e-4,\n",
    "        epochs=100,\n",
    "        verbose=True,\n",
    "        wandb_log=False,\n",
    "    )\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    with torch.no_grad():\n",
    "        pred_classes = train_model.predict_class(\n",
    "            dataloader=test_loader, batch_size=batch_size, verbose=True\n",
    "        ).to(device)\n",
    "\n",
    "    test_labels = y_test.to(device)\n",
    "    # Calculate and print metrics for each fold\n",
    "    \n",
    "    accuracy = accuracy_score( pred_classes,test_labels)\n",
    "    precision = precision_score(pred_classes,test_labels)\n",
    "    recall = recall_score(pred_classes,test_labels)\n",
    "    f1 = f1_score(pred_classes,test_labels)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(\"\\n\")\n",
    "    # Calculate and store metrics for each fold\n",
    "    accuracy_list.append(accuracy_score(pred_classes, test_labels))\n",
    "    precision_list.append(precision_score( pred_classes,test_labels))\n",
    "    recall_list.append(recall_score(pred_classes,test_labels))\n",
    "    f1_list.append(f1_score(pred_classes,test_labels))\n",
    "\n",
    "# Calculate and print the mean of metrics across all folds\n",
    "print(\"Mean Accuracy: \", sum(accuracy_list) / len(accuracy_list))\n",
    "print(\"Mean Precision: \", sum(precision_list) / len(precision_list))\n",
    "print(\"Mean Recall: \", sum(recall_list) / len(recall_list))\n",
    "print(\"Mean F1: \", sum(f1_list) / len(f1_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
