{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from os.path import expanduser, join, basename, dirname\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "from shutil import copy\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import torch\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "# from albk.data.utils import idx_to_locate\n",
    "use_disjoint_files = False\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from glob import glob\n",
    "from os.path import expanduser, join, basename, dirname\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idx_to_locate(idx):\n",
    "    file_idx = idx // 25\n",
    "    local_idx = idx % 25\n",
    "\n",
    "    lat_lag = local_idx // 5 - 2\n",
    "    lon_lag = local_idx % 5 - 2\n",
    "\n",
    "    return file_idx, lat_lag, lon_lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_common_label_files(path1, path2):\n",
    "    files1 = glob(join(path1, \"*.nc\"))\n",
    "    files2 = glob(join(path2, \"*.nc\"))\n",
    "    \n",
    "    f1_base_files = [basename(f) for f in files1]\n",
    "    f2_base_files = [basename(f) for f in files2]\n",
    "    \n",
    "    common_files = set(f1_base_files).intersection(f2_base_files)\n",
    "    common_label_files = []\n",
    "    for file in common_files:\n",
    "        ds1 = xr.open_dataset(join(path1, file))\n",
    "        ds2 = xr.open_dataset(join(path2, file))\n",
    "        if np.all(ds1.label.values == ds2.label.values):\n",
    "            common_label_files.append(file)\n",
    "    \n",
    "    return list(map(lambda f: join(path1, f), common_label_files))\n",
    "\n",
    "def get_disjoint_files(path1, path2):\n",
    "    files1 = glob(join(path1, \"*.nc\"))\n",
    "    files2 = glob(join(path2, \"*.nc\"))\n",
    "    \n",
    "    f1_base_files = [basename(f) for f in files1]\n",
    "    f2_base_files = [basename(f) for f in files2]\n",
    "    \n",
    "    disjoint_files = set(f1_base_files).symmetric_difference(f2_base_files)\n",
    "    \n",
    "    f1_disjoint = [f for f in disjoint_files if f in f1_base_files]\n",
    "    f1_disjoint = list(map(lambda f: join(path1, f), f1_disjoint))\n",
    "\n",
    "    f2_disjoint = [f for f in disjoint_files if f in f2_base_files]\n",
    "    f2_disjoint = list(map(lambda f: join(path2, f), f2_disjoint))\n",
    "    \n",
    "    return f1_disjoint + f2_disjoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moderator rishabh\n",
      "      Moderator files 0\n",
      "      Common label files 379\n",
      "      Disjoint files 1\n",
      "      Total files from rishabh and ('rishabh', 'shataxi') 379\n",
      "      Total annotatated files 379\n",
      "Total dataset size 9475\n",
      "All Brick Kilns 0\n",
      "All Non-brick Kilns 9475\n"
     ]
    }
   ],
   "source": [
    "# base_path = expanduser(\"~/bangladesh_labels/bkdb/india_labels/region/delhi/sarath_data\")\n",
    "base_path = expanduser(\"/home/jaiswalsuraj/suraj_work/Brick-Kilns-Project/bkdb/india_labels/power_plant\")\n",
    "# paths = {\"rishabh\": (\"shataxi\", \"suraj\"), \"suraj\": (\"rishabh\", \"vannsh\")}\n",
    "paths = {\"rishabh\": (\"rishabh\", \"shataxi\")}\n",
    "\n",
    "all_labeled_files = []\n",
    "for moderator, annotators in paths.items():\n",
    "    # Get moderator files\n",
    "    moderator_path = join(base_path, \"moderated\", moderator)\n",
    "    moderator_files = glob(join(moderator_path, \"*.nc\"))\n",
    "    \n",
    "    # Get annotator common label files\n",
    "    annotator1_path = join(base_path, annotators[0])\n",
    "    annotator2_path = join(base_path, annotators[1])\n",
    "    \n",
    "    common_base_files = get_common_label_files(annotator1_path, annotator2_path)\n",
    "    \n",
    "    # Get disjoint files\n",
    "    disjoint_files = get_disjoint_files(annotator1_path, annotator2_path)\n",
    "    \n",
    "    all_files = moderator_files + common_base_files\n",
    "    if use_disjoint_files:\n",
    "        all_files.extend(disjoint_files)\n",
    "    assert len(all_files) == len(set(all_files))\n",
    "    all_labeled_files.extend(all_files)\n",
    "    \n",
    "    print(\"Moderator\", moderator)\n",
    "    print(\" \"*5, \"Moderator files\", len(moderator_files))\n",
    "    print(\" \"*5, \"Common label files\", len(common_base_files))\n",
    "    print(\" \"*5, \"Disjoint files\", len(disjoint_files))\n",
    "    print(\" \"*5, f\"Total files from {moderator} and {annotators}\", len(all_files))\n",
    "    print(\" \"*5, \"Total annotatated files\", len(all_labeled_files))\n",
    "    \n",
    "print(\"Total dataset size\", len(all_labeled_files) * 25)\n",
    "def get_bk_stats(path):\n",
    "    ds = xr.open_dataset(path)\n",
    "    z = (ds.label.values == \"Z\").sum()\n",
    "    f = (ds.label.values == \"F\").sum()\n",
    "    o = (ds.label.values == \"O\").sum()\n",
    "    return {\"Z\": z, \"F\": f, \"O\": o}\n",
    "\n",
    "df = pd.DataFrame([get_bk_stats(path) for path in all_labeled_files])\n",
    "\n",
    "df_sum = df.sum(axis=0)\n",
    "\n",
    "print(\"All Brick Kilns\", df_sum[\"Z\"] + df_sum[\"F\"])\n",
    "print(\"All Non-brick Kilns\", df_sum[\"O\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/jaiswalsuraj/suraj_work/Brick-Kilns-Project/bkdb/india_labels/power_plant/rishabh/20.91,85.21.nc', '/home/jaiswalsuraj/suraj_work/Brick-Kilns-Project/bkdb/india_labels/power_plant/rishabh/16.51,77.30.nc', '/home/jaiswalsuraj/suraj_work/Brick-Kilns-Project/bkdb/india_labels/power_plant/rishabh/24.39,85.56.nc', '/home/jaiswalsuraj/suraj_work/Brick-Kilns-Project/bkdb/india_labels/power_plant/rishabh/21.28,79.12.nc', '/home/jaiswalsuraj/suraj_work/Brick-Kilns-Project/bkdb/india_labels/power_plant/rishabh/22.82,69.53.nc']\n"
     ]
    }
   ],
   "source": [
    "print(all_labeled_files[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379\n"
     ]
    }
   ],
   "source": [
    "# images_path = expanduser(\"~/bkdb/statewise/sarath_data1/\")\n",
    "images_path = expanduser(\"home/rishabh.mondal/bkdb/india_power_plant_data/\")\n",
    "# images_path = expanduser(\"/home/jaiswalsuraj/suraj_work/Brick-Kilns-Project/bkdb/india_labels/power_plant/rishabh/\")\n",
    "# images_path=expanduser('')\n",
    "# load_path = \"/home/rishabh.mondal/Brick-Kilns-project/albk_rishabh/temporary\"\n",
    "files = all_labeled_files\n",
    "# print(files)\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "ename": "GroupNotFoundError",
     "evalue": "group not found at path \"group not found at path ''\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/jaiswalsuraj/miniconda3/envs/torch_gpu/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py\", line 463, in _process_worker\n    r = call_item()\n  File \"/home/jaiswalsuraj/miniconda3/envs/torch_gpu/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/home/jaiswalsuraj/miniconda3/envs/torch_gpu/lib/python3.10/site-packages/joblib/parallel.py\", line 589, in __call__\n    return [func(*args, **kwargs)\n  File \"/home/jaiswalsuraj/miniconda3/envs/torch_gpu/lib/python3.10/site-packages/joblib/parallel.py\", line 589, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"/tmp/ipykernel_3950498/1774390474.py\", line 13, in get_index_and_image\n  File \"/home/jaiswalsuraj/miniconda3/envs/torch_gpu/lib/python3.10/site-packages/xarray/backends/zarr.py\", line 900, in open_zarr\n    ds = open_dataset(\n  File \"/home/jaiswalsuraj/miniconda3/envs/torch_gpu/lib/python3.10/site-packages/xarray/backends/api.py\", line 573, in open_dataset\n    backend_ds = backend.open_dataset(\n  File \"/home/jaiswalsuraj/miniconda3/envs/torch_gpu/lib/python3.10/site-packages/xarray/backends/zarr.py\", line 967, in open_dataset\n    store = ZarrStore.open_group(\n  File \"/home/jaiswalsuraj/miniconda3/envs/torch_gpu/lib/python3.10/site-packages/xarray/backends/zarr.py\", line 456, in open_group\n    zarr_group = zarr.open_group(store, **open_kwargs)\n  File \"/home/jaiswalsuraj/miniconda3/envs/torch_gpu/lib/python3.10/site-packages/zarr/hierarchy.py\", line 1532, in open_group\n    raise GroupNotFoundError(path)\nzarr.errors.GroupNotFoundError: group not found at path ''\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mGroupNotFoundError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 39\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28mprint\u001b[39m(index\u001b[38;5;241m.\u001b[39mdtype, images\u001b[38;5;241m.\u001b[39mdtype, labels\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m index, images, labels\n\u001b[0;32m---> 39\u001b[0m index, images, labels \u001b[38;5;241m=\u001b[39m \u001b[43mget_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(images\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(index\u001b[38;5;241m.\u001b[39mshape, images\u001b[38;5;241m.\u001b[39mshape, labels\u001b[38;5;241m.\u001b[39mshape)    \n",
      "Cell \u001b[0;32mIn[9], line 25\u001b[0m, in \u001b[0;36mget_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_data\u001b[39m():\n\u001b[0;32m---> 25\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_index_and_image\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     index \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([np\u001b[38;5;241m.\u001b[39marray(idx) \u001b[38;5;28;01mfor\u001b[39;00m idx, _, _ \u001b[38;5;129;01min\u001b[39;00m out])\n\u001b[1;32m     27\u001b[0m     images \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mconcat([torch\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnhwc->nchw\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39mconcat(imgs)) \u001b[38;5;28;01mfor\u001b[39;00m _, imgs, _ \u001b[38;5;129;01min\u001b[39;00m out])\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_gpu/lib/python3.10/site-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_gpu/lib/python3.10/site-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_gpu/lib/python3.10/site-packages/joblib/parallel.py:1699\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1692\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[1;32m   1693\u001b[0m \n\u001b[1;32m   1694\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[1;32m   1695\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[1;32m   1696\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[1;32m   1697\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[1;32m   1698\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[0;32m-> 1699\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1700\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1702\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_gpu/lib/python3.10/site-packages/joblib/parallel.py:1734\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1730\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediatly raise the error by\u001b[39;00m\n\u001b[1;32m   1731\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[1;32m   1732\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[1;32m   1733\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1734\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_gpu/lib/python3.10/site-packages/joblib/parallel.py:736\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    730\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[1;32m    732\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[1;32m    733\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[1;32m    734\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[0;32m--> 736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    738\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_gpu/lib/python3.10/site-packages/joblib/parallel.py:754\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[0;32m--> 754\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    755\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    756\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[0;31mGroupNotFoundError\u001b[0m: group not found at path \"group not found at path ''\""
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "def get_index_and_image(file):\n",
    "    index = []\n",
    "    images = []\n",
    "    labels = []\n",
    "    base_name = basename(file)\n",
    "    # print(base_name)\n",
    "    image_path = join(images_path, base_name).replace(\".nc\", \".zarr\")\n",
    "    image_path = join(images_path, base_name).replace(\".nc\", \".zarr\")\n",
    "    \n",
    "    # print(image_path)\n",
    "    label_ds = xr.open_dataset(file)\n",
    "    # print (label_ds)\n",
    "    image_ds = xr.open_zarr(image_path, consolidated=False)\n",
    "    # image = image_ds.data.reshape(-1, 224, 224, 3)\n",
    "    for lat_lag, lon_lag in product(range(-2, 3), repeat=2):\n",
    "        index.append(base_name.replace(\".nc\", \"\")+f\"_{lat_lag}_{lon_lag}\")\n",
    "        images.append(torch.tensor(image_ds.sel(lat_lag=lat_lag, lon_lag=lon_lag)['data'].values)[np.newaxis, ...])\n",
    "        labels.append(torch.tensor((label_ds.sel(lat_lag=lat_lag, lon_lag=lon_lag)['label'].values != \"O\").astype(np.uint8)))\n",
    "        \n",
    "    return index, images, labels\n",
    "\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    out = Parallel(n_jobs=32)(delayed(get_index_and_image)(file) for file in tqdm(files, total=len(files)))\n",
    "    index = np.concatenate([np.array(idx) for idx, _, _ in out])\n",
    "    images = torch.concat([torch.einsum(\"nhwc->nchw\", torch.concat(imgs)) for _, imgs, _ in out])\n",
    "    # scale\n",
    "    # images = images / 255\n",
    "    # mean normalize\n",
    "    # images = (images - images.mean(dim=(0, 2, 3), keepdim=True)) / images.std(dim=(0, 2, 3), keepdim=True)\n",
    "    \n",
    "    labels = np.concatenate([np.array(lbl) for _, _, lbl in out])\n",
    "    labels = torch.tensor(labels, dtype=torch.uint8)\n",
    "    #check the all dytpes\n",
    "    print(index.dtype, images.dtype, labels.dtype)\n",
    "    return index, images, labels\n",
    "\n",
    "index, images, labels = get_data()\n",
    "print(images.dtype)\n",
    "print(index.shape, images.shape, labels.shape)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.uint8\n",
      "torch.uint8\n"
     ]
    }
   ],
   "source": [
    "print(images.dtype)\n",
    "print(labels.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test data path# save_path=\"/home/rishabh.mondal/Brick-Kilns-project/albk_rishabh/tensor_data/test_data.pt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.uint8\n"
     ]
    }
   ],
   "source": [
    "# save the tensors data \n",
    "# print(images.dtype)\n",
    "# save_path=\"/home/rishabh.mondal/Brick-Kilns-project/albk_rishabh/tensor_data/test_data.pt\"\n",
    "# torch.save({\n",
    "#     'index': index,\n",
    "#     'images': images,\n",
    "#     'labels': labels\n",
    "# }, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
